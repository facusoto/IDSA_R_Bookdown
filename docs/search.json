[{"path":"index.html","id":"te-damos-la-bienvenida","chapter":"Capítulo 1 Te damos la bienvenida","heading":"Capítulo 1 Te damos la bienvenida","text":"¡Bienvenida/o al Curso Circular de R para Data Analytics! Este material de estudio es un complemento escencial para las clases en vivo que se dictan como parte del curso.En el panel izquierdo se encuentra detallada la tabla de contenidos, que enumera todos los temas que se cubren en el curso. Cada tema tiene su propia página, que contiene una explicación detallada del concepto y una serie de ejercicios prácticos.","code":""},{"path":"index.html","id":"curso-circular","chapter":"Capítulo 1 Te damos la bienvenida","heading":"1.1 Curso circular","text":"La estructura circular del curso te permite avanzar de manera flexible, hay un inicio establecido para el curso, por lo que podes comenzar aprender desde cualquier clase. ¡Pongamos un ejemplo! En la siguiente imagen se muestra como un alumno puede comenzar estudiar desde dos puntos totalmente distintos, el alumno es el que elige cuando iniciar la cursada y con que tema.pesar de que en este caso se refleja solo dos inicios, tu puedes comenzar desde donde quieras.\nSin embargo, se recomienda encarecidamente que si posees conocimientos previos o necesitas repasarlos entonces leas los temas de introducción los algoritmos y Elementos de probabilidad y estadística antes de profundizar en los temas más avanzados.\nSin más que decir, solo queremos recordarte que si te surgen dudas o inconvenientes olvides consultar los profesores.","code":""},{"path":"introducción-a-los-algoritmos.html","id":"introducción-a-los-algoritmos","chapter":"Capítulo 2 Introducción a los algoritmos","heading":"Capítulo 2 Introducción a los algoritmos","text":"","code":""},{"path":"diseño-y-construcción-de-un-almacén-de-datos.html","id":"diseño-y-construcción-de-un-almacén-de-datos","chapter":"Capítulo 3 Diseño y construcción de un almacén de datos","heading":"Capítulo 3 Diseño y construcción de un almacén de datos","text":"","code":""},{"path":"diseño-y-construcción-de-un-almacén-de-datos.html","id":"antecedentes","chapter":"Capítulo 3 Diseño y construcción de un almacén de datos","heading":"3.1 Antecedentes","text":"Las organizaciones en general y las empresas en particular vienen generando crecientes volúmenes de datos, desde los tiempos en que las buenas prácticas ponían foco especialmente en asegurar el ahorro de espacio de almacenamiento ya que en aquél entonces los precios del espacio de almacenamiento eran prohibitivamente caros y se buscaba reducir la cantidad de datos y aumentar la eficiencia mediante el úso de las formas normales.El cambio en los precios de almacenamiento y el creciente enfoque en el análisis de los datos vieron consigo un cambio en la forma de almacenar los datos, pasando de una organización utilizando sistemas transaccionales como CRM y LRP al Data warehouse. Esto trajo consigo un enfoque de desnormalización en los datos almacenar, lo que quiere decir que mantuvo la redundancia de datos que son de grán valor para su análisis.Los sistemas transaccionales suelen guardar la última versión de la información correspondiente, en muchos casos se \"pisan\" los datos que pueden ser relevantes.\nPor ejemplo, puede suceder que se registre que un cliente tiene deuda, pero se almacene información sobre si pagó en tiempo y forma, si pagó con retraso o si se le condonó la deuda por motivos impositivos.\nEsto ocurre con el DW ya que, desde esta perspectiva, la historia del cliente es importante y es por ello que se almacenan los datos de forma redundante.En el pasado, las empresas solían acumular la información de sus sistemas transaccionales en bases de datos relacionales y sin preocuparse demasiado por cómo se almacenaba la información. Esto resultaba en problemas la hora de extraer información útil para la empresa, ya que la extracción de masiva de datos podía poner en riezgo las operaciónes cotidianas debido sus exigencias en términos de recursos computacionales.Extraer datos masivos para analizar en los sistemas transaccionales implicaba el úso de muchos recursos, realizar esta tarea podía generar problemas de rendimiento en toda la plataforma!Debido esto era común que se recomiende que los datos analizar se movieran un almacenamiento independiente, con ello agilizamos el análisis y evitamos interrupciones o problemas en las operaciones diarias.Además, los operadores de los sistemas transaccionales se enfocaban en que el negocio siguiera su curso sin interrupciones, y siempre prestaban la atención necesaria la calidad de la información que introducían en los sistemas.Estos problemas se traducían en datos incompletos, información en campos equivocados, y otras estructuras horizontales que dificultaban la tarea analítica. En resumen, el problema radicaba en la falta de una estructura de datos adecuada y en la falta de atención la calidad de la información ingresada.Resulta decepcionantemente común encontrarse con fenómenos del tipo:\"Ah, antes del 2000 guardábamos el código postal en el campo observaciones\"\n\", la localidad recién está normalizada desde el 2003, antes era un campo libre y para los clientes ya conocidos se dejaba en blanco\"Muchos esfuerzos de análisis se estrellaron contra estos problemas. La lección duramente aprendida es que antes de aplicar las herramientas analíticas es preciso preparar los datos.\nLo que quiere decir que primero hay que eliminar los patrones de ruido, esas inconsistencias de las que hablamos.","code":""},{"path":"diseño-y-construcción-de-un-almacén-de-datos.html","id":"resumiendo","chapter":"Capítulo 3 Diseño y construcción de un almacén de datos","heading":"3.2 Resumiendo","text":"Las principales diferencias entre los sistemas transaccionales y los almacenes de datos son la velocidad, el espacio en disco y el propósito de uso.\nLos sistemas transaccionales están diseñados para realizar operaciones como insert, delete y update lo más rápido posible.\nPor su parte el DW está optimizado para ejecutar select masivos mucho más rápidamente costa del espacio en disco que se utiliza. Además, es importante mantener el registro modificable de todos los hechos guardados en él, en lugar de actualizar los datos se recomienda agregarlo nuevamente modificado.","code":""},{"path":"diseño-y-construcción-de-un-almacén-de-datos.html","id":"arquitectura-de-un-almacén-de-datos","chapter":"Capítulo 3 Diseño y construcción de un almacén de datos","heading":"3.3 Arquitectura de un almacén de datos","text":"pesar de lo mencionado anteriormente, es importante aclarar que los almacenes de datos (o DW) necesariamente representan una diferencia para el usuario final u operador, ya que en la mayoría de los casos, el sistema OLTP (o sistema transaccional) continúa siendo utilizado como fuente de datos; su vez el DW almacena de forma redundante la información del OLTP con el objetivo de análisis y consulta de datos.Entonces, un almacén de datos se integra por:Fuentes OLTPETLRepositorioGestor de consultasHerramientas de usuario finalLas aplicaciones OLTP, como los ERP, CRM, SCM, son sistemas de procesamiento transaccional en línea que son esenciales para las operaciones de las organizaciones. Sin embargo, utilizar OLTP como almacén de datos es inconveniente debido que las bases de datos relacionales que soportan nuestras aplicaciones están optimizadas para la rapidez con las que resuelven las transacciones operativas, pero son adecuadas para realizar consultas masivas.Para evitar este problema, el almacén de datos utiliza un repositorio en el que se guarda una copia de los datos y una aplicación de ETL que se encarga de extraer, transformar y cargar los datos del entorno operativo (OLTP) en el repositorio. La transformación incluye la limpieza de los datos.El repositorio está optimizado para la lectura y es el núcleo del almacén de datos. El Gestor de consultas se encarga de tomar las peticiones de los usuarios finales y resolverlas consultando el repositorio. Finalmente, la herramienta de usuario final permite los usuarios obtener distintas vistas de los datos sin tener que preocuparse por cómo están guardados.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"elementos-de-probabilidad-y-estadística---parte-1","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","text":"\nEste curso incluye una introducción sistemática los conceptos fundamentales de probabilidad y estadística. Te planteamos que si te sientes cómodo con la parte práctica, busca información adicional en un texto formal de matemáticas o consultalo al profesor.\nSi ya tienes formación formal en probabilidad y estadística, este repaso es necesario.\n","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"observaciones","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.1 Observaciones","text":"Antes de comenzar con los temas de probabilidad y estadística, es importante entender lo que significa una observación. En el contexto de la estadística, una observación es una medición o registro de una variable en un evento, objeto o individuo en particular. Por ejemplo, si se está estudiando la altura de las personas, una observación puede ser la altura de una persona en particular, medida en centímetros. Las observaciones pueden tomar diferentes formas, como valores numéricos, códigos o categorías, y pueden ser obtenidas mediante métodos como encuestas, experimentos o mediciones físicas.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"tipos-de-variables","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.2 Tipos de variables","text":"su vez, las observaciones se dividen en distintas variables respecto su tipo en cuantitativas y cualitativas.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"variables-cuantitativas","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.2.1 Variables cuantitativas","text":"Las variables cuantitativas son aquellas que se miden en términos de cantidad o magnitud numérica, y se pueden dividir en dos subtipos: variables continuas y variables discretas.Las variables continuas pueden tomar cualquier valor en un intervalo específico, como la altura o el peso de una persona.Las variables discretas solo pueden tomar valores enteros, como el número de hijos que tiene una familia o la cantidad de estudiantes en una clase.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"variables-cualitativas","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.2.2 Variables cualitativas","text":"Las variables cualitativas, diferencia, se miden en términos de características o atributos que pueden ser expresados en términos numéricos. Las variables cualitativas se dividen en dos subtipos: variables nominales y variables ordinales.Las variables nominales se refieren categorías sin un orden inherente, como el color de los ojos o la marca de un automóvil.Las variables ordinales, al contrario, tienen un orden inherente, como la escala de calificación de un examen (, B, C, D, F) o la clasificación socioeconómica de las personas (alta, media, baja).","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"agrupando-observaciones","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.3 Agrupando observaciones","text":"Teniendo en cuenta que una observación es simplemente el registro de un evento o medición, ya sea una variable cuantitativa o cualitativa, podemos pasar ver cómo éstas se organizan dentro del estudio estadístico. El conjunto de todas las observaciones existentes de una variable se denomina universo y representa el conjunto completo de datos de interés.Es importante tener en cuenta que, en muchos casos, el universo puede ser extremadamente grande o incluso infinito, lo que dificulta medir o analizar todas las observaciones. Es por ello que se utilizan técnicas de muestreo para seleccionar un subconjunto representativo de observaciones del universo.lo largo del curso utilizaremos múltiples datasets, que son más que un grupo de observaciones estructuradas y que analizaremos por medio de distintos medios y herramientas. De estos datasets se utilizarán muestras, que son una selección aleatoria o sistemática del universo de observaciones y que utilizaremos para hacer inferencias.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"tipos-de-estadística","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.4 Tipos de estadística","text":"La estadística es una rama de las matemáticas que se encarga de recolectar, analizar e interpretar datos. Su objetivo principal es el de obtener información útil partir de los datos. En general, la estadística se divide en dos grandes áreas: estadística descriptiva y estadística inferencial.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"descriptiva","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.4.1 Descriptiva","text":"Conozco el universo y quiero describirlo mediante medidas que lo resumanEs la que se encarga de recopilar, organizar, resumir, analizar y presentar los datos obtenidos de una muestra. Explora y describe los datos de manera que se puedan interpretar.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"inferencial","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.4.2 Inferencial","text":"Conozco una muestra y quiero inferir el universoEn algunos casos, la estadística descriptiva por sí sola es suficiente para obtener las conclusiones que buscamos. En estos casos se puede utilizar la estadística inferencial, es la que se encarga de tomar conclusiones partir de las muestras. Se utiliza para hacer predicciones sobre los datos partir de los resultados obtenidos en la muestra.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"probabilidad","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.5 Probabilidad","text":"En este curso utilizaremos multiples algoritmos, herramientas y métodos que nos permitirán realizar aproximaciones e información con el uso de la probabilidad, pero primero definamos de que se trata.La probabilidad se encarga de estudiar y medir la posibilidad de que un evento o suceso determinado ocurra y sus posibles resultados. En otras palabras, la probabilidad se utiliza para cuantificar la incertidumbre en una situación que involucra varios resultados posibles.Se representa numéricamente en una escala del 0 al 1, donde 0 indica que el evento es imposible de suceder y 1 indica que es seguro que ocurra. Todos los otros valores en el intervalo entre 0 y 1 indican diferentes grados de probabilidad, donde valores más cercanos 1 indican una probabilidad más alta.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"medidas","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.6 Medidas","text":"Volviendo la estadística, dentro de esta existen las diferentes medidas que resumen las observaciones en un conjunto que simplifica los datos. Por ejemplo, las medidas de altura de una clase pueden ser promedio, mediana, moda, mínimo y máximo. De esta manera, se puede tener una representación más simple de los datos que permita una mayor comprensión y análisis.\nAquí se explica brevemente algunas de ellas:Media: También conocida como promedio, es el valor obtenido al sumar todos los datos y dividir el resultado entre el número total de datos. Suele utilizarse como el valor mas representativo, aunque debe abusar de su uso porque este valor puede diferir de la realidad.Mediana: El valor que ocupa el punto medio de un conjunto de datos, el centro de los valores ordenados de menor mayor. Suele utilizarse cuando valores extremos afectan la media.Moda: Es el valor que aparece con mas frecuencia en el conjunto de datos e indica el valor mas típico o común en el conjunto.Desvío estándar: Es una medida de variabilidad, es decir, de cuán dispersos están los datos de una muestra de una población respecto la media.Percentiles: Son medidas que dividen un conjunto de datos en 100 partes iguales. El percentil 50 es la mediana, el percentil 25 es el valor que separa el 25% inferior de los datos, y el percentil 75 es el valor que separa el 75% inferior de los datos.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-1.html","id":"gráficos","chapter":"Capítulo 4 Elementos de probabilidad y estadística - Parte 1","heading":"4.7 Gráficos","text":"Los gráficos son herramientas visuales que se utilizan para representar los datos de manera clara y comprensible, existen múltiples tipos de gráficos orientados distintos tipos de datos y representaciones, continuación se explicará brevemente algunos de ellos:Barras: Utiliza los ejer cartesianos (X, Y) para representar datos discretos o categóricos, donde en alguno de los ejes se posicionan las categorías de la variable mientras que su altura o longitud representa la frecuencia de esa categoría.Líneas: Muestra la evolución de una o varias variables numéricas en el tiempo o en un eje cartesiano. Los puntos de datos están conectados por segmentos de línea recta para mostrar la tendencia o el patrón de cambio en los datos.Torta: Se trata de un círculo dividido en sectores que representan cada uno una proporción del total, la suma de los sectores es igual al 100%.Los gráficos circulares son muy criticados y deben evitarse en la medida de lo posible.Histograma: Representa la distribución de los datos por medio de columnas que muestran la frecuencia de los datos, es decir, el número de veces que aparece un valor. Es útil para detectar patrones mediante la distribución.cuantos mas datos, mejor la representación gráfica.Diagrama de dispersión: Muestra la relación entre 2 variables numéricas. Donde cada punto de datos representa una observación de ambas variables, el valor de su primera variable se representa en el eje X, el de la segunda en el eje Y.Boxplot: Ofrece un resumen de una o varias variables numéricas. La línea que divide la caja en 2 partes representa la mediana de los datos. El final del recuadro muestra los cuartiles superior e inferior. Las líneas extremas muestran el valor más alto y el más bajo excluyendo los valores atípicos.\nExiste multiplicidad de distintos gráficos disponibles, cada uno de ellos con sus particularidades y ventajas, te dejamos links continuación para que puedas continuar indagando en ello.\ndata viz\nR Graph GalleryYa vimos que son las observaciones, sus tipos, como se agrupan y como partir de éstas se puede realizar distintas medidas y gráficas. En el siguiente capítulo continuaremos conociendo más elementos y dar incapié la rama inferencial de la estadística.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-2.html","id":"elementos-de-probabilidad-y-estadística---parte-2","chapter":"Capítulo 5 Elementos de probabilidad y estadística - Parte 2","heading":"Capítulo 5 Elementos de probabilidad y estadística - Parte 2","text":"\nEste curso incluye una introducción sistemática los conceptos fundamentales de probabilidad y estadística. Te planteamos que si te sientes cómodo con la parte práctica, busca información adicional en un texto formal de matemáticas o consultalo al profesor.\nSi ya tienes formación formal en probabilidad y estadística, este repaso es necesario.\n","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-2.html","id":"distribuciones-de-probabilidad","chapter":"Capítulo 5 Elementos de probabilidad y estadística - Parte 2","heading":"5.1 Distribuciones de probabilidad","text":"En el capítulo anterior vimos lo que era la probabilidad, que es la medida de la posibilidad de que un evento ocurra en un conjunto de eventos posibles y que se expresa en valores que van desde el 0 hasta el 1. También vimos como los diferentes gráficos pueden representar los datos de distintos modos y facilitar su comprensión.Para comenzar hablar de distribuciones de probabilidad primero hablemos nuevamente del histograma, en el siguiente gráfico se muestra como, medida que la colección de datos aumenta, la cantidad de datos representados va en ascenso.Nota como los datos van en constante crecimiento y como éstos se distribuyen, principalmente, en la zona central.Esto se trata de un gráfico de distribuciones de frecuencia, el histograma puede graficar la frecuencia de los datos al apilar los datos del mismo valor. partír de la observación de múltiples distribuciones en los datos es como se crearon los modelos de distribución de probabilidad que son una contrapartida teórica de estas ya que solo muestran las veces que ocurrió un determinado evento, sinó que también cuántas veces debería haber ocurrido.Los matemáticos han descubierto varias distribuciones de probabilidad diferentes, es decir, sabemos que diferentes tipos de datos tenderán caer naturalmente en una distribución conocida y podemos usarlos para ayudarnos calcular la probabilidad. continuación se explicará algunos de ellos de forma intuitiva.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-2.html","id":"la-distribución-uniforme","chapter":"Capítulo 5 Elementos de probabilidad y estadística - Parte 2","heading":"5.1.1 La distribución uniforme","text":"La distribución uniforme es aquella que posee un número finito o continuo de variables aleatorias en la cual cada resultado posible tiene la misma probabilidad de ocurrir. Un ejemplo con un número finito de posibilidades es el lanzamiento de un dado justo, en el cual existe la misma probabilidad de sacar cualquier numero del 1 al 6, debido que todas las posibilidades tienen igual probabilidad el gráfico de dispersión es uniforme y se representa de la siguiente manera.GRÁFICO EN R","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-2.html","id":"la-distribución-binomial","chapter":"Capítulo 5 Elementos de probabilidad y estadística - Parte 2","heading":"5.1.2 La distribución binomial","text":"La distribución binomial (bi = dos, nominal = categorías) calcula las probabilidades para eventos que solo pueden tener dos resultados posibles (si o , uno o cero, cara o cruz). Esta distribución modela la probabilidad de que se observe cualquier número de éxitos en un número de observaciones discreta.Un ejemplo de ello es el arrojar una moneda justa, aunque un único lanzamiento nos dará necesariamente información de las probabilidades, por ello trabajamos con una colección de observaciones.Supongamos una colección de 10 lanzamientos, ¿Cuantas caras podríamos esperar si cada lado de la moneda es igual? (Cada lado tiene una probabilidad de 0,5), por experiencia o intuición podríamos decir que la cantidad de caras tiende ser similar la de cruces pero, ¿Que pasaría si repitieramos el experimento otras 10.000 veces? veríamos entonces como se distribuyen las probabilidades de éxito.GRÁFICO EN R","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-2.html","id":"la-distribución-normal","chapter":"Capítulo 5 Elementos de probabilidad y estadística - Parte 2","heading":"5.1.3 La distribución normal","text":"La distribución normal refleja la probabilidad de que ocurra cualquier valor para una variable continua. Ejemplos de variables contínuas son la altura o la edad, donde en una persona puede observarse en cualquier valor lo largo de un continuo, como tener 35,6 años y medir 174cm.Si se grafica estas observaciones para una población, la distribución normal te permite ver como se agrupan estos valores alrededor de un valor central (la media) y como se extiende los valores hacia los más altos y los más bajos.GRAFICO EN RLa forma de la gráfica parece una campana, donde la mayoría de los datos se encuentran cerca de la media, y conforme se aleja de la media la cantidad disminuye formando una curva simétrica.La distribución normal es simétrica, por lo que se espera que exista la misma cantidad de observaciones tanto por encima como por debajo de la media, es decir, si la media de la altura de una población se situara en 170cm se espera que el número de personas que se situan en 160cm sea igual la de 180cm. pesar de lo que se espera, y como en todas las distribuciones de probabilidad, los datos del mundo real se acercarán la distribución normal pero casi nunca coincidirán exactamente con esta.","code":""},{"path":"elementos-de-probabilidad-y-estadística---parte-2.html","id":"estadistica-inferencial","chapter":"Capítulo 5 Elementos de probabilidad y estadística - Parte 2","heading":"5.2 Estadistica inferencial","text":"En el capítulo anterior ya vimos una introducción los tipos de estadística, especialmente la estadística descriptiva. Ahora vamos extender un poco más en la rama inferencial.diferencia de la rama descriptiva, que se enfoca en describir y resumir datos través de las distintas medidas, la estadística inferencial se enfoca en hacer estimaciones o inferenias en base una muestra de nuestros datos.Si tomamos de ejemplo un set de datos, como podría ser las compras en una tienda por día, la estadística descriptiva te permitiría resumir y comprender los datos que se poseen; pero la estadística inferencial, por su parte, te permite hacer predicciones sobre el futuro partír de los que se tiene.Podría ayudarnos predecir cuantas ventas tendrá en el futuro nuestra tienda, aunque siempre y cuando nuestro set de datos sea representativo, es decir que poseamos o creemos una muestra de datos que representen correctamente la realidad.","code":""},{"path":"árboles-de-decisión.html","id":"árboles-de-decisión","chapter":"Capítulo 6 Árboles de decisión","heading":"Capítulo 6 Árboles de decisión","text":"Algoritmo:\nCategoría: Machine Learning\nAprendizaje: Supervisado\nObjetivo: Clasificación y/o regresión\nEntrada: Variables categóricas o regresivas\nSalida: Variables categóricas o regresivas\n\nCategoría: Machine LearningAprendizaje: SupervisadoObjetivo: Clasificación y/o regresión\nEntrada: Variables categóricas o regresivas\nSalida: Variables categóricas o regresivas\nEntrada: Variables categóricas o regresivasSalida: Variables categóricas o regresivas\nAntes de comenzar con el estudio y práctica de algoritmos te recomendamos leer el capítulo de introducción los algoritmos\n","code":""},{"path":"árboles-de-decisión.html","id":"que-son","chapter":"Capítulo 6 Árboles de decisión","heading":"6.1 ¿Que son?","text":"Los árboles de decisión son una herramienta útil para detectar patrones y obtener conocimiento partir de un conjunto de datos. El proceso consiste en tener un conjunto de datos de N observaciones que están definidas por M atributos, donde cada observación tiene un resultado de pertenencia (su etiqueta). El objetivo es aprender predecir este resultado de pertenencia partir de los atributos presentes.Este proceso de aprendizaje es supervisado, ya que para la construcción del árbol es necesario conocer la clase la que pertenece cada observación.Entonces podríamos decir que el algoritmo de árboles de decisión se basa en buscar las diferencias clave entre los datos utilizando sus atributos, y estos le permiten comprender bajo que circunstancias ocurre el patrón que se está buscando.Para lograr esto, el algoritmo evalúa la división que genera cada atributo y decide cuál de ellos es el que mejor permite dividir los datos en subgrupos homogéneos o puros (que comparten características en común), este proceso se repite iterativamente utilizando los distintos atributos y generando así distintos niveles de subgrupos. En cada nivel del árbol, se usan métricas como la ganancia de información o la impureza del nodo para calcular la \"pregunta óptima\" (es decir evaluar el atributo óptimo) fin de dividir los datos en grupos más pequeños. Este proceso se repite hasta que los datos se hayan dividido lo suficiente como para predecir un resultado o hasta llegar una condición de corte.\nEs un algoritmo muy noble, ya que permite tanto la entrada como salida de variables categóricas o regresivas, se lo puede utilizar como clasificador o como regresor , esto lo hace muy adaptable, ejecuta rápido y el resultado es legible por humanos\n","code":""},{"path":"árboles-de-decisión.html","id":"partes-del-árbol","chapter":"Capítulo 6 Árboles de decisión","heading":"6.2 Partes del árbol","text":"La construcción de árboles de decisión consiste en ir partiendo el conjunto de observaciones en forma sucesiva. Cada división la vamos llamar nodo. Cuando un nodo conduzca nuevas divisiones se denomina hoja, pero hasta entonces estos nodos también son considerados como ramas del árbol (ya que conducen distintos nodos del árbol)","code":""},{"path":"árboles-de-decisión.html","id":"partes-del-árbol-1","chapter":"Capítulo 6 Árboles de decisión","heading":"6.3 Partes del árbol","text":"La construcción de árboles de decisión consiste en ir partiendo el conjunto de observaciones en forma sucesiva. Cada división la vamos llamar nodo. Cuando un nodo conduzca nuevas divisiones se denomina hoja, pero hasta entonces estos nodos también son considerados como ramas del árbol (ya que conducen distintos nodos del árbol)","code":""},{"path":"árboles-de-decisión.html","id":"las-métricas-de-decisión","chapter":"Capítulo 6 Árboles de decisión","heading":"6.4 Las métricas de decisión","text":"Para lograr evaluar los atributos y tomar decisiones el algoritmo realiza distintas métricas, este se plantea \"preguntas\" (es decir evalúa atributos) en cada uno de los niveles del árbol y aplica una división que asegure mayor pureza cada nodo que crea. Algunas de las métricas que utiliza para este fin son:","code":""},{"path":"árboles-de-decisión.html","id":"ganancia-de-información","chapter":"Capítulo 6 Árboles de decisión","heading":"6.4.1 Ganancia de información","text":"La ganancia de información es una métrica que mide cuanto aumenta el nivel de certeza luego de la división, es decir mide la diferencia de entropía antes y después de la división. Podemos pensar en la ganancia de información y la entropía (aleatoriedad) como opuestos, donde si el nivel de entropía baja la ganancia de información o certeza aumenta.","code":""},{"path":"árboles-de-decisión.html","id":"impureza-del-nodo","chapter":"Capítulo 6 Árboles de decisión","heading":"6.4.2 Impureza del nodo","text":"La impureza del nodo es una métrica que mide la impureza de los datos en un nodo. Existen distintos tipos de impureza, como la entropía, el índice Gini o el error de clasificación. Cada uno de estos se mide de manera diferente aunque su objetivo es el mismo, medir que tan mezclados están los datos respecto sus atributos.","code":""},{"path":"árboles-de-decisión.html","id":"usos-del-algoritmo","chapter":"Capítulo 6 Árboles de decisión","heading":"6.5 Usos del algoritmo","text":"Una de las ventajas de los árboles de decisión es que son robustos ante la presencia de ruidos o errores en los conjuntos de entrenamiento, lo que los hace útiles en situaciones en las que los datos pueden ser completamente precisos. Además, los árboles de decisión son una herramienta adaptable, de ejecución rápida y fáciles de interpretar por humanos, lo que los hace útiles en una amplia gama de aplicaciones, algunos ejemplos de sus usos son:MEJORAR","code":""},{"path":"árboles-de-decisión.html","id":"los-algoritmos-de-árboles","chapter":"Capítulo 6 Árboles de decisión","heading":"6.6 Los algoritmos de árboles","text":"Es importante aclarar que existe un único algoritmo capaz de realizar árboles de decisión, existen diferentes métodos y librerías que nos permiten realizarlo, cada una con sus ventajas y desventajas asociadas, algunos de los algoritmos desarrollados mas difundidos son:COMPLETAR","code":""},{"path":"árboles-de-decisión.html","id":"poda-y-sobreajuste","chapter":"Capítulo 6 Árboles de decisión","heading":"6.7 Poda y sobreajuste","text":"En la explicación sobre los algoritmos de árboles de decisión explicamos que estos se continúan subdividiendo hasta lograr lo \"suficiente como para predecir un resultado\". Sin embargo, esto siempre es así, de hecho, algunos algoritmos continúan subdividiéndose hasta que solo quedan hojas o hasta que ya hay más atributos que utilizar. Pero, ¿realmente todas las subdivisiones son útiles para predecir?Además, como se mencionó en la introducción los algoritmos, para trabajar con este algoritmo primero se debe construir los conjuntos de entrenamiento y prueba.Es aquí donde se vuelve valioso haber utilizado estos conjuntos. Al comparar el árbol obtenido al utilizar el conjunto de entrenamiento con los datos de prueba, se pueden eliminar todas las subdivisiones que cumplan con los estándares de calidad.Estas subdivisiones que aportan valor predictivo y cumplen con los estándares de calidad se denominan sobreajuste. Es decir, se enfocan en cualidades casuales de la muestra que representan el universo del que provienen. El proceso de eliminar estas subdivisiones se llama poda y se puede clasificar en:Prepoda: Se realiza durante la construcción del árbol y antes de que alcance la profundidad máxima. Cuando las subdivisiones posibles para un nodo superan determinado factor de calidad entonces este nodo se considera una hoja y se detiene su división.Postpoda: Se realiza la división hasta el final y se eliminan desde el final todos los nodos o ramas que aportan información relevante o que incluso pueden reducir la precisión del modelo. Esto se logra evaluando el valor de cada una de ellas en comparación los datos de testeo y se elimina las que mejoran el modelo.Re-estructuración: Cuando se trabaja con árboles de decisión, veces puede ocurrir que el conjunto de casos sea conocido desde el principio, sino que se van conociendo en el tiempo. En estos casos, puede ser conveniente empezar la división de una manera distinta la que se hubiera hecho si se conociera todo el conjunto de antemano. Este proceso permite modificar la estructura del árbol medida que se van obteniendo nuevos datos.","code":""},{"path":"árboles-de-decisión.html","id":"ejercicios","chapter":"Capítulo 6 Árboles de decisión","heading":"6.8 Ejercicios","text":"","code":""},{"path":"árboles-de-decisión.html","id":"ejercicio-1","chapter":"Capítulo 6 Árboles de decisión","heading":"6.8.1 Ejercicio 1","text":"Para comenzar con los ejercicios utilizaremos la librería rpart que crea, partír de un conjunto de datos, un árbol de decisión que puede utilizarse para pronosticar con la función predict(). Para ello primero descarga el dataset de la clase Descarga el archivo aquíEl dataset que utilizaremos es una colección observaciones sobre la altura de personas, el objetivo del ejercicio es poder utilizar los atributos para aprender predecir.Una vez descargado el archivo procedemos leerlo, utilizamos función read.csv y lo almacenamos en una variable, continuación veamos la estructura del dataset utilizando str()El dataframe posee 1000 líneas y 4 variables, estas representan lo siguiente:.padre: altura del padrea.madre: altura de la madres.hijo: sexo del hijoa.hijo: altura del hijoEntonces ya sabemos de que se trata el dataset, es una tabla que indica la altura de dos padres y el género y altura de su hijo, nuestro objetivo es ver la relación que existe entre estos valores.Comenzamos por cambiar los valores de s.hijo de carácteres factores","code":"\n# Cambiamos el path a la dirección en donde se encuentra nuestro archivo\nread_csv <- read.csv(\"path/to/file.csv\")\nstr(read_csv)## 'data.frame':    1000 obs. of  4 variables:\n##  $ a.padre: int  170 190 160 170 180 170 230 150 150 180 ...\n##  $ a.madre: int  170 170 140 140 160 160 150 150 150 160 ...\n##  $ s.hijo : chr  \"M\" \"F\" \"F\" \"M\" ...\n##  $ a.hijo : int  180 150 130 160 150 170 160 130 160 150 ...\nread_csv$s.hijo <- as.factor(read_csv$s.hijo)\nstr(read_csv)## 'data.frame':    1000 obs. of  4 variables:\n##  $ a.padre: int  170 190 160 170 180 170 230 150 150 180 ...\n##  $ a.madre: int  170 170 140 140 160 160 150 150 150 160 ...\n##  $ s.hijo : Factor w/ 2 levels \"F\",\"M\": 2 1 1 2 1 2 1 1 2 1 ...\n##  $ a.hijo : int  180 150 130 160 150 170 160 130 160 150 ..."},{"path":"algoritmos-de-agrupamiento.html","id":"algoritmos-de-agrupamiento","chapter":"Capítulo 7 Algoritmos de agrupamiento","heading":"Capítulo 7 Algoritmos de agrupamiento","text":"Algoritmo:\nCategoría: Machine Learning\nFuncionamiento: supervisado\nObjetivo: Agrupamiento\nEntrada: Variables categóricas o regresivas\nSalida: Conjuntos de grupos\n\nCategoría: Machine LearningFuncionamiento: supervisadoObjetivo: Agrupamiento\nEntrada: Variables categóricas o regresivas\nSalida: Conjuntos de grupos\nEntrada: Variables categóricas o regresivasSalida: Conjuntos de grupos\nAntes de comenzar con el estudio y práctica de algoritmos te recomendamos leer el capítulo de introducción los algoritmos\n","code":""},{"path":"algoritmos-de-agrupamiento.html","id":"qué-son","chapter":"Capítulo 7 Algoritmos de agrupamiento","heading":"7.1 ¿Qué son?","text":"Los algoritmos de agrupamiento, también conocidos como clustering en inglés, son técnicas que permiten agrupar un conjunto de puntos (observaciones) distribuidos en un espacio de varias dimensiones. Estos puntos son agrupados de acuerdo criterios de proximidad, que pueden variar dependiendo de la métrica utilizada para definir dicha proximidad, algunas de las métricas más comunes son la euclídea y la matriz de correlación.El objetivo de estas técnicas es obtener grupos de observaciones que compartan características o atributos similares y que, su vez, estos grupos se diferencien entre sí. Los grupos obtenidos permiten describir e identificar patrones y estructuras del conjunto de datos complejo.\nEs importante destacar que estas técnicas de clustering funcionan sin supervisión y poseen poder predictivo alguno. Es decir, buscan encontrar relaciones entre variables descriptivas y una variable objetivo (o etiqueta), sino que se enfocan en encontrar similitudes entre los datos sin tener una variable objetivo de referencia.\n","code":""},{"path":"algoritmos-de-agrupamiento.html","id":"criterios-de-proximidad","chapter":"Capítulo 7 Algoritmos de agrupamiento","heading":"7.2 Criterios de proximidad","text":"Cuando se habla de criterios de proximidad en algoritmos de agrupamiento, se refiere la medida en que los objetos del conjunto de datos están cerca entre sí. La proximidad se puede medir de diversas formas, y esto depende del tipo de datos que se esté analizando y del objetivo del análisis.En el caso de datos que se pueden representar en un espacio dimensional, la proximidad física puede medirse mediante la distancia euclidiana, la cual mide la distancia entre dos puntos en un espacio de n dimensiones.Sin embargo, en algunos casos, los atributos en común pueden ser una mejor medida de proximidad. Es decir, dos objetos pueden considerarse cercanos en función de su similitud en ciertas características, incluso si están cerca físicamente en el espacio de características.Podemos dividir los algoritmos de agrupamiento en dos grandes tipos, el agrupamiento jerárquico y el jerárquico.","code":""},{"path":"algoritmos-de-agrupamiento.html","id":"agrupamiento-jerárquico","chapter":"Capítulo 7 Algoritmos de agrupamiento","heading":"7.3 Agrupamiento jerárquico","text":"En el clustering jerárquico se apunta agrupar los datos en forma de árbol (también conocido como dendrograma). Este árbol puede ser formado tanto por la aglomeración como la división de las observaciones.","code":""},{"path":"algoritmos-de-agrupamiento.html","id":"aglomerativos-bottom-up","chapter":"Capítulo 7 Algoritmos de agrupamiento","heading":"7.3.1 Aglomerativos (bottom up)","text":"En este caso se comienza considerando cada punto como un grupo separado y, en cada paso, los grupos más similares se fusionan hasta que se obtiene un solo grupo. El resultado final es una jerarquía de grupos en forma de árbol que pueden ser interpretados diferentes niveles de agregación.","code":""},{"path":"algoritmos-de-agrupamiento.html","id":"de-división-top-down","chapter":"Capítulo 7 Algoritmos de agrupamiento","heading":"7.3.2 De división (top down)","text":"Este caso podría decirse que es el inverso, se comienza utilizando el conjunto entero de observaciones y se va subdividiendo hasta llegar elementos individuales.","code":""},{"path":"algoritmos-de-agrupamiento.html","id":"agrupamiento-no-jerárquico","chapter":"Capítulo 7 Algoritmos de agrupamiento","heading":"7.4 Agrupamiento no jerárquico","text":"En los agrupamientos jerárquicos, el operador decide el número de divisiones. Se agrupan las observaciones según su cercanía, buscando grupos heterogéneos pero con elementos homogéneos en su interior.\nAunque en ocasiones son muy robustos en cuanto los resultados que ofrecen, su uso está muy extendido, especialmente el método k-medias (o k-means).\n","code":""},{"path":"algoritmos-de-agrupamiento.html","id":"k-means","chapter":"Capítulo 7 Algoritmos de agrupamiento","heading":"7.4.1 K-means","text":"El objetivo de k-means es agrupar puntos de datos similares en un número de clústeres predefinido por el usuario. El proceso se realiza en varias iteraciones hasta que se llega un punto donde los clusters se estabilizan y cambian más.El algoritmo funciona midiendo la distancia entre cada punto de datos en un espacio n-dimensional. Cuanto más cerca estén dos puntos de datos, más similares serán y cuanto más alejados, menos similares.Para ejemplificar el procedimiento utilizaremos un set de datos simple. Los datos se representan como círculos blancos ubicados en un espacio de dos dimensiones, también se discierne 3 grupos de datos distintos.El algoritmo utiliza centroides que son simplemente un término para referirse al centro de un cluster. Por lo tanto, el número de centroides corresponderá al número de clusters que se creen.En la primera iteración del algoritmo se colocan los centroides en posiciones aleatorias del espacio de datos. partir de ahí cada punto de datos se asignará al centroide más cercano, lo que crea los grupos iniciales.Aquí se puede ver los centroides asignados en lugares aleatorios del espacio (Los círculos de mayor tamaño) y como los datos son asignados un grupo al tomar el color del centroide.En la siguiente fase, se calcula el centro del grupo y se mueven los centroides hacia allí. Tras moverse los centroides, se reasignarán los puntos de datos los nuevos centroides más cercanos y se repite el proceso hasta que los centroides ya se muevan y los grupos se estabilizan.Como se puede ver, los centroides se aproximaron los diferentes grupos de datos\nEstos gráficos fueron creados utilizando la herramienta de visualización de k-means de  NaftaliHarris\n","code":""},{"path":"reglas-de-asociación.html","id":"reglas-de-asociación","chapter":"Capítulo 8 Reglas de asociación","heading":"Capítulo 8 Reglas de asociación","text":"Algoritmo:\nCategoría: Machine Learning\nAprendizaje: Supervisado y supervisado\nObjetivo: Descubrimiento de asociaciones\nEntrada: Variables categóricas\nSalida: Reglas de asociación\n\nCategoría: Machine LearningAprendizaje: Supervisado y supervisadoObjetivo: Descubrimiento de asociaciones\nEntrada: Variables categóricas\nSalida: Reglas de asociación\nEntrada: Variables categóricasSalida: Reglas de asociación\nAntes de comenzar con el estudio y práctica de algoritmos te recomendamos leer el capítulo de introducción los algoritmos\n","code":""},{"path":"reglas-de-asociación.html","id":"qué-son-1","chapter":"Capítulo 8 Reglas de asociación","heading":"8.1 ¿Qué son?","text":"Las reglas de asociación son una técnica en el análisis de datos que se utiliza para identificar patrones y relaciones entre distintos atributos de un conjunto de datos, es especialmente útil en el análisis de grandes conjuntos de datos transaccionales.Las reglas de asociación generalmente toman la forma de \"si ocurre , entonces es probable que también ocurra B\" donde y B son atributos. Por ejemplo, \"Si un cliente compra pan, es probable que también compre manteca\".Las reglas de asociación se forman partir de la frecuencia con la que se observan grupos de atributos juntos en los datos. Es decir, si un conjunto de atributos aparecen juntos con frecuencia en los datos, se considera que hay una relación entre ellos. Por ejemplo, si en un supermercado se observa que los clientes que compran pañales también compran cerveza con frecuencia, se puede establecer una regla de asociación que diga \"si un cliente compra pañales, entonces es probable que también compre cerveza\".Para descubrir estas reglas, se utiliza un algoritmo llamado Apriori, que es capaz de buscar conjuntos de atributos que se producen con frecuencia en el conjunto de datos mediante el uso de las medidas de cobertura y confianza, de las que vamos desarrollar continuación","code":""},{"path":"reglas-de-asociación.html","id":"conceptos","chapter":"Capítulo 8 Reglas de asociación","heading":"8.2 Conceptos","text":"Antes de continuar con el funcionamiento del algoritmo veamos algunos conceptos asociados.","code":""},{"path":"reglas-de-asociación.html","id":"hands","chapter":"Capítulo 8 Reglas de asociación","heading":"8.2.1 Hands","text":"Es importante comprender que en reglas de asociación se nombra de distinto modo cada parte de la relación. Las reglas del tipo “si X entonces Y” se pueden expresar modo de fórmula, como aparece continuación:\\[X \\Rightarrow Y\\]Tal que podemos hablar de \"lados de la flecha\", donde en el lado izquierdo de la regla recibe el nombre de antecedente o left-hand-side (LHS) y el lado derecho el nombre de consecuente o right-hand-side (RHS).Entonces dentro de una regla del tipo:\"Si un cliente compra leche y pan, entonces es probable que también compre manteca\"Identificamos \"compra de leche\" y \"compra de pan\" como antecedenteconsecuente y \"compra de manteca\" como antecedenteconsecuente","code":""},{"path":"reglas-de-asociación.html","id":"cobertura-o-soporte","chapter":"Capítulo 8 Reglas de asociación","heading":"8.2.2 Cobertura o soporte","text":"Una de las medidas principales que utiliza el algoritmo Apriori es la de cobertura, que se refiere la frecuencia con la que se observa un conjunto de atributos juntos en el conjunto de datos.La cobertura se mide como la proporción de casos observados del antecedente (el conjunto de atributos en la parte izquierda de la regla) dividido entre el total de casos. El resultado es un número entre cero y uno, donde uno indica que todos los casos cumplen la regla, se intentará encontrar conjuntos de atributos donde su cobertura sea lo más alta posible\\[\\Large{\\frac{\\text{Casos que cumplen la regla}}{\\text{Casos totales}}}\\]\nEs importante tener en cuenta que la cobertura puede variar entre el conjunto de entrenamiento y el conjunto de validación si se han aleatorizado adecuadamente los valores, lo que puede llevar resultados incorrectos.\n","code":""},{"path":"reglas-de-asociación.html","id":"confianza","chapter":"Capítulo 8 Reglas de asociación","heading":"8.2.3 Confianza","text":"En muchas ocasiones la aparición de ciertos conjuntos de atributos en un conjunto de datos puede estar relacionada con la presencia de otros conjuntos de atributos. La relación entre estos conjuntos puede ser cuantificada través de la confianza, que es otra medida utilizada en el algoritmo Apriori para identificar reglas de asociación.La confianza mide la proporción de casos en los que se observa el consecuente (el atributo en la parte derecha de la regla) dado que se observa el antecedente (el conjunto de atributos en la parte izquierda de la regla). Esta proporción se calcula dividiendo los casos que posean tanto el antecedente y el consecuente entre los que solo posean el antecedente.. El resultado es un número entre cero y uno, un alto valor de confianza indica que si el antecedente está presente, es probable que también lo esté el consecuente.\\[\\Large\\text{Confianza} = \\frac{\\text{soporte(Casos antecedente y consecuente)}}{\\text{Casos antecedente}}\\]","code":""},{"path":"reglas-de-asociación.html","id":"lift","chapter":"Capítulo 8 Reglas de asociación","heading":"8.2.4 Lift","text":"Otro procedimiento importante al generar reglas de asociación es asegurar la veracidad de nuestras reglas. El lift compara la frecuencia observada de una regla con la frecuencia esperada simplemente por el azar. Esto nos permitirá determinar si la regla existe realmente o . El resultado será un número que, cuanto más se aleje de 1, mayor será la evidencia de que la regla es un patrón real.","code":""},{"path":"reglas-de-asociación.html","id":"matriz-de-interés","chapter":"Capítulo 8 Reglas de asociación","heading":"8.2.5 Matriz de interés","text":"La matriz de interés es una importante herramienta para el análisis de las reglas que hayamos generado, ya que permite determinar la correlación entre el antecedente y el consecuente de una regla al hacer una serie de preguntas sobre la relación entre ambas partes en diferentes escenarios.Se trata de una tabla que muestra la frecuencia con la que se cumplen las cuatro posibles combinaciones de la presencia o ausencia del antecedente y del consecuente. Estas combinaciones son:Antecedente y consecuente presentesAntecedente presente y consecuente ausenteAntecedente ausente y consecuente presenteAntecedente y consecuente ausentesPara cada combinación, se calcula el número de veces que ocurre en el conjunto de datos. Esto permite determinar si existe una correlación entre la presencia o ausencia del antecedente y del consecuente.","code":""},{"path":"reglas-de-asociación.html","id":"apriori","chapter":"Capítulo 8 Reglas de asociación","heading":"8.3 Apriori","text":"El algoritmo Apriori comienza buscando conjuntos de elementos que ocurren con una frecuencia mayor o igual un valor de umbral predefinido. Este umbral es el soporte mínimo y lo establece el usuario antes de ejecutar el algoritmo.COMPLETAR","code":""},{"path":"reglas-de-asociación.html","id":"casos-de-uso","chapter":"Capítulo 8 Reglas de asociación","heading":"8.4 Casos de uso","text":"Las reglas de asociación se utilizan para generar, reconocer y aprender nuevos patrones modo de regla (Recordando una regla como \"si y B se cumplen, entonces C también se cumple\"), por ejemplo:Sistemas de recomendación: través del comportamiento previo de los usuarios se puede deducir qué productos recomendarles los próximos.Sistemas de contratación: Aplicar distintas estrategias para obtener atributos de los aplicantes modo de seleccionar los que posean aquellas características más deseables.Supermercados: Se utiliza para generar cercanía física entre los productos que se compran normalmente juntos y maximizar sus ventas.","code":""},{"path":"redes-neuronales.html","id":"redes-neuronales","chapter":"Capítulo 9 Redes neuronales","heading":"Capítulo 9 Redes neuronales","text":"\nAntes de comenzar con el estudio y práctica de algoritmos te recomendamos leer el capítulo de introducción los algoritmos\n","code":""},{"path":"series_temporales.html","id":"series_temporales","chapter":"Capítulo 10 Series temporales","heading":"Capítulo 10 Series temporales","text":"Algoritmo:\nCategoría: Machine Learning\nAprendizaje: Supervisado\nObjetivo: Predicción\nEntrada: Variables ordenadas en el tiempo\nSalida: Valores futuros - Predicción\n\nCategoría: Machine LearningAprendizaje: SupervisadoObjetivo: Predicción\nEntrada: Variables ordenadas en el tiempo\nSalida: Valores futuros - Predicción\nEntrada: Variables ordenadas en el tiempoSalida: Valores futuros - Predicción\nAntes de comenzar con el estudio y práctica de algoritmos te recomendamos leer el capítulo de introducción los algoritmos\n","code":""},{"path":"series_temporales.html","id":"que-son-1","chapter":"Capítulo 10 Series temporales","heading":"10.1 ¿Que son?","text":"Una serie temporal es una colección de observaciones de una variable aleatoria tomadas en forma secuencial medida que transcurre el tiempo.Estas mediciones se utilizan para predecir cómo la variable se comportará en el futuro. Por lo tanto, se examina el comportamiento de la serie temporal en el pasado para inferir su comportamiento en el futuro.En las series temporales, las observaciones sucesivas están relacionadas entre sí. Por lo tanto, el análisis debe respetar el orden temporal en el que se producen las mediciones. Esto significa que los métodos estadísticos que asumen la independencia de las observaciones son válidos para el análisis de series temporales, ya que los valores en un momento en el tiempo dependen de los valores de la serie en el pasado.El propósito del análisis de series temporales es describir la serie temporal y comprender cómo se comporta lo largo del tiempo. Esto incluye examinar si la serie temporal presenta una tendencia creciente, si hay una influencia estacional o si hay observaciones extrañas. Esta información se puede utilizar para hacer predicciones sobre el comportamiento futuro de la serie temporal.","code":""},{"path":"series_temporales.html","id":"clasificaciones-de-las-series-temporales","chapter":"Capítulo 10 Series temporales","heading":"10.2 Clasificaciones de las series temporales","text":"Las series temporales se pueden clasificar en cuatro categorías principales: discretas, continuas y determinísticas, estocásticas.","code":""},{"path":"series_temporales.html","id":"de-acuerdo-a-la-frecuencia-de-los-datos","chapter":"Capítulo 10 Series temporales","heading":"10.2.1 De acuerdo a la frecuencia de los datos:","text":"Las series discretas: Se toman valores de forma constante, generalmente en intervalos regulares.Las series continuas: Tienen un valor para cada momento.","code":""},{"path":"series_temporales.html","id":"de-acuerdo-a-la-forma-de-predicción","chapter":"Capítulo 10 Series temporales","heading":"10.2.2 De acuerdo a la forma de predicción:","text":"Las series determinísticas: Se pueden predecir con precisión.Las series estocásticas: Dependen de las observaciones pasadas, pero también de factores aleatorios, por lo que solo se pueden predecir de forma aproximada.","code":""},{"path":"series_temporales.html","id":"aspectos-de-una-serie-temporal","chapter":"Capítulo 10 Series temporales","heading":"10.3 Aspectos de una serie temporal","text":"Tendencia: Son aquellas que muestran un patrón general de aumento o disminución en el tiempo. Se refiere al comportamiento de la serie largo plazo, generalmente con un promedio que toma en cuenta varios períodos.Gráfico con tendencia subidaEstacionalidad: Estas series muestran patrones periódicos, como el desempleo que aumenta en invierno y disminuye en verano.Casos de gripe través de los años, muestra una estacionalidad en los inviernosComponente Aleatorio: Es la parte restante de la serie temporal, y se puede tratar de capturar usando un modelo probabilístico para estimar los desvíos en las predicciones.<img src=\"images/st-aleatorio.png>Eventos aleatorios que definen el precio de BitcoinDe estas tres componentes, las dos primeras, resultan determinísticas mientras que la tercera es estocástica.","code":""},{"path":"series_temporales.html","id":"predicción-estocástica","chapter":"Capítulo 10 Series temporales","heading":"10.4 Predicción estocástica","text":"Las series temporales estocásticas serán nuestro enfoque ya que son las que presentan mayor dificultad la hora de establecer un modelo que permita predecir los valores futuros, para ello se utiliza el modelo ARIMA.Enfoque ARIMA: Supone que los datos de la serie temporal que se está intentando pronosticar provienen de un proceso aleatorio o estocástico. Esto significa encontrar qué proceso generó los datos, estimar los parámetros relevantes para ese proceso, verificar que las hipótesis sean válidas y luego usar el modelo para predecir el futuro con base en lo observado.Para el caso, utilizaremos ARIMA habiendo previamente eliminado / suprimido los aspectos de tendencia y estacionalidad de la serie temporal. Para ello se utilizan distintas herramientas y estrategias.","code":""},{"path":"series_temporales.html","id":"desdiferenciación","chapter":"Capítulo 10 Series temporales","heading":"10.4.1 Desdiferenciación","text":"Diferenciación de la serie se refiere una técnica usada para intentar eliminar la tendencia de una serie temporal. Esto se logra restando el valor en el instante actual \\(t\\) de su valor en el instante anterior, \\(t-1\\). Esto genera una nueva serie cuyo comportamiento es más predecible y fácilmente analizable ya se ve menos afectada por la tendencia.\nLuego, usando análisis de Fourier podemos encontrar el período que tiene sentido para nuestro problema y desestacionalizarla calculando los promedios lo largo de toda la serie.","code":""},{"path":"series_temporales.html","id":"desestacionalización","chapter":"Capítulo 10 Series temporales","heading":"10.4.2 Desestacionalización","text":"Una vez que hemos identificado el período más largo relacionado con nuestro problema (Cada serie tendrá su periodicidad particular), podemos desestacionalizar la serie original calculando el promedio lo largo de toda la serie (por ejemplo semanas).Se logra al dividir cada valor de la serie original por el promedio obtenido.Esto nos da un mejor conocimiento sobre lo que está sucediendo en nuestra serie: como la oscilación anual, armónicos superiores, aumento lineal, etc.","code":""}]
